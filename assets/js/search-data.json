{
  
    
        "post0": {
            "title": "Trustworthy Online Controlled Experiments",
            "content": ". &#128640; The book in 3 sentences . [Still reading the book] . &#127912; Impressions . [Still reading the book] . &#9752;&#65039; How the book changed me . [Still reading the book] . &#9997;&#65039; My top 3 quotes . &quot;Most who have run controlled experiments in customer-facing websites and applications have experienced this humbling reality: we are poor at assessing the value of ideas&quot; | . Twyman&#39;s Law: &quot;Any figure that looks interesting or different is usually wrong&quot; - A.S.C. Ehrenberg || &quot;The more unusual or interesting the data, the more likely they are to have been the result of an error&quot; - Catherine Marsh and Jane Elliott | . &#128210; Summary + Notes . Part 1: Introductory topics for everyone . 1. Introduction and motivation . The book starts with an anecdote from Bing where an employee had proposed a new idea for how ad headlines should be displayed. The basic idea was to make the title longer by combining it with text from the first line under the title. Nobody seemed to think much of this idea and it was stashed into the backlog of experiments for six months before a software engineer decided to test the idea. . This simple change ended up increasing revenue by 12%, which translated to more than $100 million dollars in the US alone annually without hurting other important metrics. . A few takeaways from this event are that it&#39;s very hard to predict the value of an idea (this one ended up being forgotten during 6 months) and small changes can have huge impacts. For this reason it is important to have infrastructure in place that makes experimenting very cheap. Bing runs more than 10.000 experiments per year and the great majority don&#39;t have this kind of results. . There are many types of controlled experiments. The main focus of this book is on a specific type of controlled experiment called an A/B test. The basic idea is to split users randomly between a control version and a variant. . Another very important concept is the Overall Evaluation Criterion (OEC). This could be a single metric or a combination of different metrics. The most important thing to remember is that the OEC has to be measurable in the short-term and believed to have a causal relationship with long-term success according to established strategic objectives. . Think about the ad headline example. If the success metric was only revenue, it wouldn&#39;t take long before the whole site was full of ads. This could definitely increase revenue in the short-term, but would probably turn users off in the long-term causing them to switch over to friendlier alternatives. . When designing a controlled experiment, it is common to choose a parameter or set of parameters. These are variables that we think are going to have an impact on the OEC. These parameters are going to take on different values for each variant. . It is also important to thoughtfully set up the randomization process. This is the secret sauce of controlled experiments. The basic intuition behind this is that if there is no other factor influencing assignment apart from proper randomization, then on average we would expect both groups to be similar on all factors except the parameter we are changing. This means that any observed effect on the OEC should with very high probability be an effect of that change and nothing else. . This leads us into a conversation around correlation, causality and trustworthiness. The authors present a slightly silly but true example by sharing that the number of error messages has a strong inverse correlation with churn. Should we then increase the number of error messages or intentionally add bugs to the code of Office 365? Obviously not, because error messages don&#39;t cause lower churn. It turns out that power users tend to churn less and bump into more error messages just because they use the product more than other users. . &quot;We believe online controlled experiments are the best scientific way to establish causality with high probability&quot; . Of course, it&#39;s not always possible to run a controlled experiment. For example, we can&#39;t create two alternate realities where we buy another company in one reality and we don&#39;t buy the other company in the other reality to see which option is better. . The authors list a series of ingredients that need to be present to be able to run a controlled experiment:1. Experimental units, like users, that can be assigned to each variant without interference where users in one group could affect the actions of the users of the other group. . Enough experimental units. The authors recommend to be at least in the thousands. The more units we have the more granular we can be in our experiments and discover smaller effects that are harder to detect. | Key metrics that are easy to understand, agreed upon and can be measured easily. If possible, the OEC should be used. A proxy metric can be used if the main metric is too difficult or slow to measure. | Easy changes. The harder it is to create a variant, the harder it becomes to run a controlled experiment. This is one of the reasons software has become an ideal playground for running controlled experiments. | The authors also present three tenets or key beliefs that any organization needs to run online controlled experiments: . The organization wants to make data-driven decisions and has formalized an OEC | Obviously, most people will say that data-driven decision-making is important for them. Still, in practice it is very common to plan, execute and declare success based on how much of the plan was accomplished while ignoring the impact on key metrics. . In contrast, for data-driven decision-making to exist we need a clearly defined OEC (or set of OECs) that is measurable in the short term (1 to 2 weeks) and predictive of long-term success. This way we can quickly evaluate if what we are doing tactically and strategically is actually having a real impact on our OEC. . The organization is willing to invest in the infrastructure needed to run and test controlled experiments so that results are trustworthy | In some domains, like healthcare, it can be considered unethical or illegal to run certain controlled experiments. In other domains, like hardware production, changes can be slow and expensive. . In general, software is a great option because it tends to be relatively easy to randomly split users between variants, log the results and iteratively add changes to the software. Still, the organization still has to be willing to invest in setting up the necessary tests and processes so that results are trustworthy at scale. . The organization recongizes that it is poor at assessing the value of ideas | Based on quotes from experts at Microsoft, Google, Netflix, Slack and others, the authors claim that most teams see experiment success rates of 10-33%, with most of them being on the lower end. In other words, we can expect 70-90% of our work to be thrown away due to poor or even negative results. . &quot;Most who have run controlled experiments in customer-facing websites and applications have experienced this humbling reality:we are poor at assessing the value of ideas&quot;. . 2. Running and analyzing experiments . This chapter focuses on the principles of designing, running and analyzing experiments. . It starts with a story about a hypothetical e-commerce site where some employees have proposed the idea of adding coupon codes to the checkout process. This implies a change to the business model because the company has not offered discount codes before. Another employee mentions that research has actually shown that coupon codes could have a negative effect (users get distracted or abandon the flow completely until they can get a code). . The team decides to try out a fake door or painted door apporach. The analogy is to create a fake door or paint a door on the wall and see how many try to open it. This is a cheap way of testing an idea without having to build the whole feature first. . Now the team has to choose their OEC. Revenue seems reasonable but the total sum can be misleading because, even if the process is randomized, one variant might end up with more users than the other which would skew the results. So revenue-per-user is a better choice. . Still, the definition doesn&#39;t stop there. How do we define a user? Is it every user that visits the site? Only the users that purchase? The authors recommend users who start the purchase process because these are the users that are exposed to the variants and we need to know how this affects their next decisions. . The final hypothesis to test would be &quot;Adding a coupon code option to the checkout process has a negative impact on revenue-per-user for users who start the purchase process&quot; . At this point it is important to remember a few key concepts related to hypothesis testing: . When analyzing the key metric it is important to capture its mean value and standard error. In other words, we usually don&#39;t know the true value of the metric. So we use data estimate a mean value (other statistics can also be used) and the standard error tells us how variable this estimate is. | . Sensitivity is the ability to detect statistically significant results (true positives). This concept goes hand in hand with statistical power, the probability of detecting a meaningful result when there really is one. This ability usually gets better with smaller standard errors. This makes intuitive sense. If we have a box filled with balls and almost all of them have the same color (low variablity) we can be pretty certain of the color of a ball if we pick it randomly. If we have a lot of different colors with equal distribution (high variablity) it becomes extremely difficult to guess the correct color. It is often possible to improve sensitivity by exposing more users to the experiment. We have to be careful though because are often additional costs with more users. | . Control vs treatment samples. In this particular type of experiments we are usually not trying to estimate one value directly. We are often more interested in the difference between two values. In this case, we define a Null hypothesis, our assumption of how the world works, as the mean value of our control group being the same as the mean value of our treatment group. If we then look at the data and find this assumption to be unlikely (e.g. there is a very large difference between the sample means) we reject the null hypothesis and say that the difference is statistically significant. | . To make the previous decision, we calculate the p-value for the difference. This is the probability of observing the difference between our sample means (or a more extreme difference) assuming that the null hypothesis is true. If this probability (the p-value) is very low, it means that observing this difference is very unlikely and that&#39;s why we go on to reject the null hypothesis. | . For this to work, we have to decide on a threshold before we run our experiment, usually known as the significance level. A common standard is 0.05 which means that if there really is no difference between the two samples then we will correctly conclude this 95 out of each 100 experiments on average. Seen from another perspective, we will conclude that the difference is statistically significant even if there actually was no real difference (a false positive) about 5% of the time. | . Finally, there is also the question of practical significance. For a more personal example, would it be worth it to take on the challenge and costs of moving to another country with no family and friends for a 1% increase in salary keeping everything else equal (job requirements, benefits, etc.)? Probaby not, but a larger difference might actually be worth it. Here the question is, how large does the difference have to be so that it is practically meaningful? | . Now that we have a hypothesis, a significance boundary and a metric we also need to answer these questions to finish the design of the experiment: . What is the randomization unit? (Users is the most common) | What population of the randomization unit are we going to target? (All users vs a specific segment) | How large does the population of our experiment have to be? | How long do we have to run the experiment? | . There are multiple factors we can take into account for the size of the population. If the metric is binary (yes/no) or if we don&#39;t care about very granular differences we can use smaller populations. This is also the case for larger p-value thresholds or significance levels. In other words, if we are willing to make more mistakes then we don&#39;t need very large populations. . Of course, this leads us to other kinds of questions. If the importance of the experiment is very high then we might need larger populations to increase our certainty of the results. The opposite is true if we suspect that the change could have a negative effect on users. In that case we might have to start with a smaller population and slowly increase the size to reduce risk of a negative impact. . Also, if we run multiple experiments at the same time, each variant will probably end up with less users. . The duration of the experiment is also impacted by several factors. First of all, if we need more users we often have to allow the experiment to run for a longer period of time because not all users are exposed to the experiment simultaneously. . A primacy effect might cause users to behave differently when they first see the change so we&#39;ll also have to wait longer to see if this behavior persists or not. It is also important to keep seasonality or day-of-week effects in mind. We might have to run the experiment longer than necessary from a theoretical stanpoint just to include different dates in the experiment. . There are two main components for running the experiment: . Infrastructure to run the experiment. This includes the possibility of randomizing, presenting different variants, etc. . | Instrumentation to log how users are interacting with the variants and to calculate how the OEC is affected by the experiment. . | . Before analyzing the results, it is important to also run sanity checks on our experiment. . This usually includes guardrail metrics and invariants. In the first case we might want to check the sample sizes so that they match with the expected proportions. Some guardrail metrics are also expected to be invariant for the experiments. For example, latency should not change between variants unless the change was specifically designed to alter the latency. . With all this in place, we can now interpret the results and make decisions. The principles we have covered exist specifically so we can trust our experiments repeatedly and thus be able to make the right decisions based on the data. . For this reason, it is important to understand the business implications of our experiments so that we can modify statistical and practical significance levels before we start the experiment. This includes the costs of building the feature if the experiment is successful, cost of maintenance, effects on other important metrics, etc. . 3. Twyman&#39;s law and experimentation trustworthiness .",
            "url": "https://kallebylin.github.io/bylin/books/2021/05/01/trustworthy-controlled-experiments.html",
            "relUrl": "/books/2021/05/01/trustworthy-controlled-experiments.html",
            "date": " • May 1, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "A more beautiful question",
            "content": ". &#128640; The book in 3 sentences . En pocas palabras, una prueba A/B es una comparación entre dos alternativas con el objetivo de descubrir cuál es mejor. . Cuando tomamos decisiones es muy fácil dejarnos llevar por nuestras opiniones. Esto no siempre es malo, pero es especialmente peligroso en empresas cuando una iniciativa es seleccionada basado principalmente en la opinión de la persona . &#127912; Impressions . &#9752;&#65039; How the book changed me . &#9997;&#65039; My top 3 quotes . &quot;To encourage or even allow questioning is to cede power&quot; | . &quot;Forming questions helps us to organize our thinking around what we don&#39;t know&quot; - Stephen Quatrano, The Right Question Institute | . - . &#128210; Summary + Notes . Introduction: Why Questions? . The author&#39;s interest in questioning started when he was interviewing some of the most innovative minds for a series of articles and a book he wrote. One common denominator he found was that they were all very good as asking questions. . For many of them, their breakthrough products, solutions or services started with a key question or a series of questions that they asked and then answered. . Interestingly though, most companies and schools don&#39;t teach or encourage good questioning. It is often seen as a waste of time, rebellion towards authority or as a sign of ignorance. Therefore, obedience and memorization is often favored in these settings. . The title of the book was borrowed from this quote: . &quot;Always the beautiful answer who asks a more beautiful question&quot; - E. E. Cummings . It is then worth asking ourselves why questioning is not as common as we could except. To answer this we have to remember that questions tend to disrupt processes and structures that already exist. Questions also force us to wonder if things could be done differently. So, in a way, encouraging people to ask questions implies giving up power. . After a great number of interviews and borrowing from well-known theories in areas like design thinking, the author crated a three-part model to formulate and tackle big, beautiful questions:- Why?- What if? . How? | . The author also finishes the introduction with his own subjective definition of a beautiful question: . &quot;A beautiful question is an ambitious yet actionable question that can begin to shift the way we perceive or think about something and that might serve as a catalyst to bring about change&quot;. . Chapter 1: The Power of Inquiry . This story starts with the emotional but very powerful story about Van Phillips, who lost his leg in a water-skiing accident in the late 1970s. In the hospital he was given a prosthetic leg of wood and foam rubber. . Inspired by the technological advances by NASA and the space program, Phillips asked &quot;Why can’t a prosthetic leg perform more like a human one?&quot; and &quot;Why can’t it bend and flex, enabling a person to run and jump?&quot; . In the beginning, many felt these questions as a challenge to the doctors and prosthetics engineers who were experts in the field. . &quot;It [questioning] often has an inverse relationship to expertise. Such that, within their own subject areas, are apt to be poor questioners&quot;. . In the end, Phillips discovered that he would have to answer the question himself. . Mark Noonan, inventor of the wheeled shovel, has said that if we never do anything about a problem ourselves, then we are not really questioning. We are complaining. . Fast-forwarding several years, Phillips work has impacted the lives of thousands of people and many of us heave seen or heard the story about South Africa’s Oscar Pistorius (aka “the blade runner”), the first double-amputee runner to compete in the Olympics. He ran with a pair of carbon-fiber prosthetic legs known as Cheetahs, created by Van Phillips. . After this, the author focuses on different types of questions and how they have been used in the past. . For example, open questions tend to encourage more creative answers than closed questions, even though these are also important. . The tone is also very important. When presented with a problem, asking &quot;Oh my God, what are we going to do?&quot; is very different to asking &quot;What if this change represents an opportunity for us?&quot; or &quot;How can we make the most of this situation?&quot;. The second type of questions usually produces better answers. . David Cooperrider, from Case Western Reserve University, is one of the creators of the appreciative inquiry model. This model assumes that the questions we ask tend to focus our attention in a specific direction. One interesting result of this would be that organizations evolve in the direction of the questions they most persistently and passionately ask. . &quot;Forming questions helps us to organize our thinking around what we don&#39;t know&quot; - Stephen Quatrano, The Right Question Institute . The author also sees a very strong connection between innovation and questioning. In some sense, innovation means trying to find and formulate new questions that can be answered over time. It is very common for new businesses or products to be born from a good question. . Over time, the value of good questions have been rising. In today&#39;s world it tends to be very easy to find answers in most cases. With so much information available to us, it becomes very difficult to know which questions to ask. . We see this same phenomenon with computers, they are extremely efficient at giving us answers we are looking for but they are still not capable of producing valuable questions consistently. . The last part of the chapter focuses on the main stages of innovative questioning and the author&#39;s three-part model:- Why: Confronting, formulating and framing the initial questions that define the problem we have identified. This corresponds to the &quot;why?&quot; moment because we are trying to understand why the problem exists, why it creates an opportunity/need/pain and for whom. We also want to understand why others have not solved it and why it should be important to us. It is common for these &quot;why&quot; questions to be discovered in our daily lives. . What if: We take the understanding we have gained in the previous stage and formulate hypotheses to solve the problem. This is the first step in moving from just asking to action. The author also mentions the concepts of contextual inquiry and connective inquiry. We use the first type when we are trying to get more context about the problem we are interested in. Connective inquiry is the kind of questions we use when we start to combine knowledge from other fields or domains with the problem at hand. This produces questions like &quot;What if a prosthetic leg could have the same strength and flexibility as a springboard so that the person could jump?&quot; | . How: Decide on a specific solution, build prototypes and/or construct a plan. This is where most of the action happens. Questions tend to be much more practical (e.g. &quot;How do I test this idea?&quot; or &quot;How can I get this to work?&quot;). | . Chapter 2: Why we stop questioning . This chapter starts with the apparently never-ending ability of small children to ask questions. Unfortunately, studies show that as they grow up the number of questions that they ask falls drastically and by middle school questioning has practically stopped. . One interesting finding is that one main reason children ask why over and over again is because they feel their question has not been answered. In other words, it&#39;s their way of saying &quot;you are not hearing me, you still don&#39;t understand what I&#39;m asking&quot;. . As children move into more standardized learning, it seems like we are robbing them of the opportunity to explore and discover questions on their own. Many schools and teachers are tasked with filling up our heads with as many answers as possible based on a list of topics that have to be taught. This leaves very little time for questions that deviate from the topics that have to be covered. Children are forced to sit still in class and memorize as much as possible. . This raises the question &quot;what if our schools could train students to be better life-long learners and better adapters to change by enabling them to be better questioners?&quot; . This chapter includes the story of Deborah Meier who started applyting experimental approaches to learning in the 60s and 70s in Harlem. . Her school focused on 5 key learning skills or habits of mind, each of which had been paired to a series of questions: . Evidence: How do we know what is true or false? What evidence counts? | Viewpoint: How might this look like if we were in someone else&#39;s shows or looked at it from another perspective? | Connection: Is there a pattern? Have we seen something like this before? | Conjecture: What if it were different? | Relevance: Why does it matter? | . Her approach was based on questions, but many viewed this as undisciplined and without structure. Meier&#39;s response to this was that children are easier to control when they have the freedom to focus on what they were interested in. .",
            "url": "https://kallebylin.github.io/bylin/books/2021/04/27/a-more-beautiful-question.html",
            "relUrl": "/books/2021/04/27/a-more-beautiful-question.html",
            "date": " • Apr 27, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Smart Business",
            "content": "Author: | Genre: | Date finished: | . The book in 3 sentences . . En pocas palabras, una prueba A/B es una comparación entre dos alternativas con el objetivo de descubrir cuál es mejor. . Cuando tomamos decisiones es muy fácil dejarnos llevar por nuestras opiniones. Esto no siempre es malo, pero es especialmente peligroso en empresas cuando una iniciativa es seleccionada basado principalmente en la opinión de la persona . Impressions . How the book changed me . My top 3 quotes . Summary + Notes .",
            "url": "https://kallebylin.github.io/bylin/books/2021/04/18/smart-business.html",
            "relUrl": "/books/2021/04/18/smart-business.html",
            "date": " • Apr 18, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Pruebas A/B - Fundamentos",
            "content": "&#191;Qu&#233; es una prueba A/B? . . En pocas palabras, una prueba A/B es una comparación entre dos alternativas con el objetivo de descubrir cuál es mejor. . Cuando tomamos decisiones es muy fácil dejarnos llevar por nuestras opiniones. Esto no siempre es malo, pero es especialmente peligroso en empresas cuando una iniciativa es seleccionada basado principalmente en la opinión de la persona con mayor poder jerárquico en lugar del mérito propio de la iniciativa. . A lo largo de este documento vamos a presentar también ciertas reglas importantes durante el proceso de comparación que nos permiten tener confianza en el resultado. . Voy a enfocarme principalmente en decisiones relacionadas al desarrollo de productos digitales, pero es aplicable en muchos otros contextos. . Es una herrmiante de toma de decisiones . El valor principal de una prueba A/B nace de la incertidumbre inherente de nuestras decisiones. Cuando no estamos seguros de qué camino tomar, una prueba A/B es una manera efectiva de probar ambas alternativas por un tiempo y dejar que los resultados nos guíen. . Es un acelerador de procesos . El riesgo y la incertidumbre suelen volver lentos nuestros procesos. Cuando hay riesgo de algo potencialmente dañino para la compañía se vuelve importante crear procesos de verificación y puntos de control antes de lanzar una iniciativa. Desarrollando software es común usar una mezcla entre pruebas automatizadas y revisiones de código. . El problema es que por cada persona que tiene que entrar a revisar el trabajo tardas más en sacar la iniciativa a producción y esas personas pierden la posibilidad de estar trabajando en otra cosa. . Una prueba A/B reduce el riesgo porque te permite controlar el daño potencial y te permite justificar tus decisiones. Esto se puede hacer, por ejemplo, corriendo el experimento con únicamente 5% de tus usuarios. . Además, al comparar los resultados de tu experimento es más fácil darse cuenta si la iniciativa está teniendo un impacto negativo en alguna métrica clave. Sin un punto de comparación suele ser muy difícil saber si un cambio negativo en una métrica se debe a la implementación o algún otro factor. . Empodera personas . El uso constante de pruebas A/B reduce la necesidad de que una sola persona tome decisiones y permite a cualquier miembro del equipo aportar ideas. Se vuelve menos importante si alguien piensa que es una buena o mala idea, el desempeño de la idea en el campo de batalla es el juez final srgún los datos recolectados. . Los experimentos controlados salvan vidas . Las pruebas A/B son mucho más que una simple herramienta para optimizar la tasa de conversión en una página web. . En 1753, el médico naval escocés James Lind publicó su A Treatise of the Scurvy en el que describe una serie de experimentos controlados ofreciendo diferentes soluciones a los miembros de la tripulación. Esto le permitió llegar a la conclusión de que agregar cítricos a la dieta podría ayudar a prevenir y curar el escorbuto. . &#191;C&#243;mo funcionan las pruebas A/B? . [Trabajo en proceso] .",
            "url": "https://kallebylin.github.io/bylin/spanish/data-science/ab-testing/2021/04/17/ab-testing-basics-spanish.html",
            "relUrl": "/spanish/data-science/ab-testing/2021/04/17/ab-testing-basics-spanish.html",
            "date": " • Apr 17, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Computational Learning Theory - Notes",
            "content": "About . There are good and bad practices for human learning. Highlighting interesting quotes in a book usually makes us feel productive in the moment but, let&#39;s be honest, doesn&#39;t help much in terms of learning. . Taking notes, on the other hand, is a much more effective way of interiorizing information and storing it in long-term memory, especially if we translate concepts with our own words instead of just copying a text. . The same is true for learning algorithms, not the part about taking notes but the fact that there ar good and bad methods for learning. Computational Learning Theory (also known as Statistical Learning Theory) is a branch of computer science focused on understanding how computational learning can happen efficiently and effectively, as well as discovering different impediments to learning. . This document contains my notes on Computational Learning Theory. . Is bias always a bad thing? . Bias usually has a very negative connotation, often thought of as prejudice and we are encouraged to always keep an open mind. . But don&#39;t confuse an open mind with an empty mind. We often learn by building new ideas on top of other ideas we have learned in the past. Keeping an open mind means that we have to remember that some of our foundational building blocks might be wrong and need to be corrected. But constantly throwing away previous knowledge would make learning practically impossible. . Pigeon superstition . One of B.F. Skinner&#39;s classical experiments supposedly showed &quot;superstitious&quot; behavior by pigeons. The experiment consisted in providing food to hungry pigeons in a cage through a mechanism that was guaranteed to be completely independent from any behavior by the pigeons. . &quot;If a clock is now arranged to present the food hopper at regular intervals with no reference whatsoever to the bird&#39;s behavior, operant conditioning usually takes place. The bird tends to learn whatever response it is making when the hopper appears. The response may be extinguished and reconditioned. The experiment might be said to demonstrate a sort of superstition. The bird behaves as if there were a causal relation between its behavior and the presentation of food, although such a relation is lacking&quot;. . Skinner, B. F. (1948). &#39;Superstition&#39; in the pigeon. Journal of Experimental Psychology, 38(2), 168–172. . Let&#39;s say one of the pigeons was pecking on a prticular stain on the bottom of the cage when the first round of food was released. According to Skinner, the pigeon was then more likely to repeat this same behavior which, in turn, also made it more likely for the pigeon to be found pecking on the stain when the next round of food was released. . Amusingly, each pigeon showed a different type of behavior that was reinforced (walking around the cage in a specific direction, bobbing the head, etc.) as if the behavior was causing more food to be released. We know that this is not the case, because the food was being released at regular pre-defined intervals. . This can then be compared to different forms of human superstition. Have you or anybody you known ever had a special ritual at home before every game of our favorite football team? =D . Rats and selective association . The phenomenon above can be compared to the behavior of rats as studied by Garcia and Koelling in 1966. Imagine rats going for their regular snack. Some of the rats were then induced to feel ill through an injection or radiation. As could be expected these rats then avoided food with similar taste or smell in the future. . Another batch of rats was administered a mild electrical shock in the foot. Interestingly, these rats did not show aversion to the food or water, but instead to an audiovisual cue that always happened while they were eating or drinking. . This experiment is widely known as one of the first proofs of the so-called Selective Association Effect. This is related to the concept of biological constraints disccused by students of Skinner. Apparently some animals naturally resist certain types of conditioning, as if they had some kind of built in prior knowledge that some types of relationships could not causal. . Inductive bias . This takes us to the concept of inductive bias, which can be described as the set of assumptions or prior knowledge that biases learning by setting restrictions or constraints to the learning process. . In our example, the rats seem to be biased towards detecting certain types of patterns between taste or smell and their health, while ignoring other types of seemingly correlated events. . This is a well known concept in machine learning. We often talk about models that have high bias or high variance. The second type of models tend to be more complex and are more flexible in the type of functions they can model. But this often makes them more difficult to interpret or prone to overfitting (they memorize the training data, which in this case can be compared to finding superstitious patterns that only apply to that particular set of data). . By restricting the types of patterns we are looking for we can often make the learning process easier and also extract valuable insights from the trained model. Linear regression is a great example with well-known assumptions and very powerful applications. . Deductive vs Inductive reasoning . Just as a refresher, we can think about deductive and inductive reasoning as taking to different routes (often described as top-down or bottom-up approaches). . On one hand (deduction) we start with general theories about how things should work, we develop a hypothesis that we can then confirm through experiments and specific observations. . Deductive reasoning:- Theory -&gt; Hypothesis -&gt; Observations -&gt; Confirmation . On the other hand, we might start with specific observations which we then use to try to discover a pattern in those observations. These patterns that we discover can then lead us to a more generalized understanding of the world. . Inductive reasoning: . Observations -&gt; Pattern -&gt; Tentative Hypothesis -&gt; Theory | . Statistical Learning Theory . In statistics it is common to to have well-defined assumptions about the distribution of our data (e.g. Gaussians). In SLT we have no or very general assumptions. . Is all learning equal? . Intuitively it would seem that there are different ways of learning. More formally, we can separate learning by different levels: . Reproductive learning | It could be argued that this first level is not learning at all. . Basically, imagine a class where students are allowed to to take all of their notes to class. It would be possible for a student to create a table with all the information he needs without interiorizing the concepts. Once the exam starts he simply looks up the answers to his questions in the table. So he basically reproduces the information. . The negative side is that we need to store all of the relevant information beforehand. This can in many cases be very difficult or even impossible. . Rule-based learning | This level of learning can be thought of as encoding the knowledge of experts. Imagine a medical application created to automatically diagnose different types of diseases. One way to do this would be to get input from a group of doctors and create a flow-chart with nodes for every single decision that could be made. . Now we don&#39;t need to store the raw data or the observations with their corresponding labels as we would do in reproductive learning. Instead we keep all of these rules that can lead us to an answer. . The problem with this approach is that it is also very difficult or even impossible to encode every single use case and the rules are often very brittle. . Creative learning | Here past experience is combined in different ways to solve new problems. This can often be a much more powerful approach as we are not limited to only reproducing past observations or following rigid rules. . The main issue here is that it can be quite difficult to explain why a decision has been made. . &quot;If the true classifier is a halfspace, then we should be able to find a very precise separation line with only a few random examples.&quot; . 1-nearest neighbor algorithm . In this extreme example we store all observations and their lables. Any new lable receives the label of the closest point. Two main conclusions we notice are:- This algorithm will always classify all training samples correctly. . This algorithm will also be able to approximate any smooth function, even where halfspace classifiers perform poorly. | . def true_classifier(point) : return int(point[0] &gt;= 0) def nearest_neighbor(train_set, test_point): closest_dist = float(&#39;inf&#39;) closest = -1 for features, label in train_set: dist = sum([(p2-p1)**2 for p1,p2 in list(zip(features, test_point))]) if dist &lt; closest_dist: closest_dist = dist closest = label label = closest return label def error_probability(train_set) : mistakes = 0 no_test_points = 2000 for i in range(0,no_test_points): point = (2*i/no_test_points - 1,) if true_classifier(point) != nearest_neighbor(train_set, point) : mistakes += 1 return mistakes/no_test_points train_inputs = [-1.0, -0.1, 0.1] new_input = -0.0001 #-0.0010000000000000009 S = [((x_val,), true_classifier((x_val,))) for x_val in train_inputs] error_S = error_probability(S) new_point = (new_input,) S.append( (new_point, true_classifier(new_point)) ) print(error_S, error_probability(S)) assert error_S &lt; error_probability(S) . 0.0005 0.025 .",
            "url": "https://kallebylin.github.io/bylin/machine-learning/computational-learning-theory/2021/03/09/computational-learning-theory.html",
            "relUrl": "/machine-learning/computational-learning-theory/2021/03/09/computational-learning-theory.html",
            "date": " • Mar 9, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Deep Learning - Notes",
            "content": "About . This notebook contains my notes for introductory DL concepts. . What is a perceptron? . Perceptrons were originally brain models created to understand how the brain works. A perceptron as we know it encodes several principles about how the brain works and then evolved into an algorithm for supervised binary classification. | . In the 1960&#39;s, Frank Rosenblatt published the book Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. It is curious that this fundamental block for AI was, in the author&#39;s mind, a tool for understanding the human brain and not for pattern recognition (even though he encouraged this use as well): . For this writer, the perceptron program is not primarily concerned with the invention of devices for &quot;artificial intelligence&quot;, but rather with investigating the physical structures and neurodynamic principles which underlie &quot;natural intelligence&quot;. A perceptron is first and foremost a brain model, not an invention for pattern recognition [emphasis added]&quot; (p. viii). . In other words, the perceptron is actually a simplification and abstraction which has allowed us to discover principles for how the brain works. These same principles were then also used to create pattern recognition machines. . Rosenblatt explicitly recognizes that his model is a direct descendant of the model created by McCulloch and Pitts, and influenced by the theories of Hebb and Hayek. . Main components of a perceptron in Rosenblatt&#39;s book:- Environment: The environment generates the information that is initially passed on to the perceptron. . Signal generating units: Each unit receives a signal and generates an output signal. | . Signal propagation functions: These are rules that define how signals are generated and transmitted. | . Memory functions: These are rules that define how properties of the perceptron can be changed in response to certain activity. | . The definition of a single neuron evolves from the ideas above. . A neuron takes values from its environment (e.g. x1, x2, x3) and each of these gets multiplied by a stored parameter (e.g. w1, w2, w3). The sum of each of these operations is then passed through an activation function. . In other words, it&#39;s as if we are trying to pass a signal through the neuron and all of these components work together to establish how the signal is transmitted. . We can imagine three old batteries used to turn on a machine. Turning it on with too little energy could cause it to break, so we check the current before passing it on to the machine. . . In the example below, we are randomly initializing the parameters. The activation function is a step-function with a threshold of 4. This means that the signal is only passed on as a unitary value if it is larger than or equal to the threshold. . import numpy as np w1 = np.random.random()*2 # generates random floats between 0 and 2 w2 = np.random.random()*2 w3 = np.random.random()*2 print(f&#39;W1 is equal to: {w1}&#39;) print(f&#39;W2 is equal to: {w2}&#39;) print(f&#39;W3 is equal to: {w3} n&#39;) x1 = 2 x2 = 1 x3 = 3 b = 0 activation_function = lambda x: 1 if x &gt;=4 else 0 output = activation_function(x1*w1 + x2*w2 + x3*w3) print(&#39;Output:&#39;, output) if output == 1: print(&#39;The machine is on!&#39;) else: print(&#39;Not enough energy to turn on the machine :(&#39;) . W1 is equal to: 0.6321002815675523 W2 is equal to: 1.6995522179113192 W3 is equal to: 1.2072466687862997 Output: 1 The machine is on! . What is an activation function? . Going back to Rosenblatt&#39;s book, activation functions are essentially signal propagation functions. . When a neuron receives a signal, the activation function decides if the signal is passed on and how strong the output signal becomes. . We already learned about the step function. This activation is often not ideal for multiple reasons. . First of all, the result is binary. But sometimes we are more interested in also knowing the degree of certainty, so I probability might be better. . We might also want to have a wider range of values. When predicting age, for example, binary values of 0 or 1 will be of little value. . A lot of different activation functions have been developed by researchers. Three common activation functions are: . Sigmoid function Has a great property of having outputs between 0 and 1 and therefore can be interpreted as probabilities. The function is also smooth and easy to differentiate which makes learning easier. . It can be problematic when the input signal has very large positive or negative values. At those points the derivative is very close to 0 and learning becomes very slow. . Hyperbolic function This is another smooth function with a range of values between -1 and 1. This is interesting because sometimes a signal might have a reverse effect on the output and the hyperbolic function allows us to include this type of relationship in the network. . Rectified linear unit (ReLU) This function is very simple aned fast to compute. This allows us to work with larger and more complex models that, given enough data, can produce better results overall. . What is a neural network? . A neural network is a directed system of connected neurons which is capable of propagating a signal received from the environment and produces an output signal. | . The neurons are generally organized in different layers which allow us to break free from linearity. . Linearity means that we are also assuming monotonicity. In other words, an increase in an input value always increases the output value if the corresponding weight is positive (and will always decrease the output value if the weight is negative). . This works fine in examples like the one seen above where we turn on a lightbulb depending on how much energy we get from each battery. . But this makes less sense in other cases. For examples very pronounced sales spikes in an online marketplace followed by no sales at all could be indicative of fraud. A positive value for a feature describing this type of spikes should increase the probability of fraud. . But is this always the case? . What if we additionally know that the owner of the store is a web celeb (网红) on Alibaba? In that case the spikes above are expected, and therefore a positive value for this feature should decrease the probability of fraud while any other behavior might be suspicious. . Let&#39;s build a neural network step by step: . The simplest example is a single neuron with only one parameter which does not modify the signal in any way: . def nn(x, w): return w*x print(nn(3, 6)) . 18 . Most processes we find in the real world are not this simple. We need to take into account multiple input features. . I love music, imagine I want to predict if I will like a particular song or not. We can quickly multiply each input value by its corresponding weight using a dot product. . def nn(X, W): return W.dot(X) x1 = 3.5 # length of songs in minutes x2 = 0 # binary value indicating if the genre is jazz or not x3 = 0 # binary value indicating if the artist is Nicki Minaj or not x4 = 1 # binary value indicating if the artist is Alan Walker X = np.array([x1, x2, x3, x4]) W = np.array([1., 0.3, -3, 4]) print(nn(X, W)) . 7.5 . What is interesting above is that the weights actually encode certain information about my taste in music. I really don&#39;t like when a song is too short and, in general, I&#39;m not fond of music by Nicki Minaj (notice the negative weight). But I do love music by Alan Walker. Jazz is nice but I don&#39;t love it. . Now the real question is, how do we know the values of these weights. In this case, I used my deep expertise regarding my own music taste to set the weights. But we would usually be more interested in doing this for the users of our streaming platform at scale. Millions of people we have never and will probably never meet in person. . So, first we&#39;re going to change the output. We want to predict if a particular user is going to like a song or not. Using the sigmoid function we can directly compare the true values (0 or 1) to our predictions (floats between 0 and 1). . We will also initialize the weights randomly and print out an error value showing how close our prediction is to the true value: . def nn(X, y, W): prediction = W.dot(X) error = y-prediction print(&#39;Predicted value:&#39;, round(prediction, 3)) print(&#39;Error:&#39;, round(error, 3)) x1 = 3.5 # length of songs in minutes x2 = 0 # binary value indicating if the genre is jazz or not x3 = 0 # binary value indicating if the artist is Nicki Minaj or not x4 = 1 # binary value indicating if the artist is Alan Walker X = np.array([x1, x2, x3, x4]) y = 5 W = np.random.random(size=4)*2-1 nn(X, y, W) . Predicted value: -1.468 Error: 6.468 . It&#39;s now time to start talking about learning or how our neural network is going to choose the best parameters during training to make accurate predictions. . We will follow a very simple framework of three steps: . Predict | Compare | Learn | This time we will add multiple iterations to our algorithm and we will do the three steps above during each iteration. . def nn(X, y, W): print(f&#39;True value: {y} n&#39;) for i in range(10): prediction = W.dot(X) error = y-prediction print(&#39;Predicted value:&#39;, round(prediction, 3)) print(&#39;Error:&#39;, round(error, 3)) if error &gt; 0: W += 0.01 else: W -= 0.01 x1 = 3.5 # length of songs in minutes x2 = 0 # binary value indicating if the genre is jazz or not x3 = 0 # binary value indicating if the artist is Nicki Minaj or not x4 = 1 # binary value indicating if the artist is Alan Walker X = np.array([x1, x2, x3, x4]) y = 1 W = np.random.random(size=4)*2-1 nn(X, y, W) . True value: 1 Predicted value: 0.116 Error: 0.884 Predicted value: 0.161 Error: 0.839 Predicted value: 0.206 Error: 0.794 Predicted value: 0.251 Error: 0.749 Predicted value: 0.296 Error: 0.704 Predicted value: 0.341 Error: 0.659 Predicted value: 0.386 Error: 0.614 Predicted value: 0.431 Error: 0.569 Predicted value: 0.476 Error: 0.524 Predicted value: 0.521 Error: 0.479 . Here we are doing hot &amp; cold learning. After each prediction we are making a comparison just like in the classical game so that we get &quot;hotter&quot; or closer to the true answer after each guess. . The way we are calculating the error makes it negative if it was too high or positive if our guess was too low. . We can now be a bit smarter in the way we learn. Instead of guessing and trying to jiggle the output to both sides, we can use the gradient to guide us: . def nn(X, y, W): print(f&#39;True values: {y} n&#39;) n = y.shape[1] for i in range(100): predictions = W.dot(X.T) mse = (1/2)*np.mean((y-predictions)**2) if i % 10 == 0: print(&#39;Mean Squared Error:&#39;, round(mse, 3)) dW = -(1/n)*(y-predictions).dot(X) W -= 0.1*dW print(&#39; nW:&#39;, np.round(W, 3)) print(&#39; nFinal predictions:&#39;, np.round(predictions, 2)) X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]]) y = np.array([[1, 0, 0, 1]]) W = np.random.randn(1, 2) nn(X, y, W) . True values: [[1 0 0 1]] Mean Squared Error: 0.234 Mean Squared Error: 0.132 Mean Squared Error: 0.078 Mean Squared Error: 0.046 Mean Squared Error: 0.028 Mean Squared Error: 0.017 Mean Squared Error: 0.01 Mean Squared Error: 0.006 Mean Squared Error: 0.004 Mean Squared Error: 0.002 W: [[0.927 0.073]] Final predictions: [[0.92 0.07 0. 1. ]] . This version led us quickly very close to the correct answers. But we now have another problem. The previous problem was very easy to learn because one of the features had a direct 1-on-1 relationship with an output. A simple linear function was capable of leveraging that feature. . Let&#39;s look at the next example: . X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]]) y = np.array([[1, 1, 0, 0]]) W = np.random.randn(1, 2) nn(X, y, W) . True values: [[1 1 0 0]] Mean Squared Error: 0.863 Mean Squared Error: 0.572 Mean Squared Error: 0.408 Mean Squared Error: 0.311 Mean Squared Error: 0.254 Mean Squared Error: 0.219 Mean Squared Error: 0.198 Mean Squared Error: 0.186 Mean Squared Error: 0.178 Mean Squared Error: 0.174 W: [[0.462 0.204]] Final predictions: [[0.47 0.2 0. 0.67]] . MSE might not be extremely high but the answers are terrible. This is because the new problem we&#39;re working with cannot be solved with a simple linear function. So, to solve this we can add a hidden layer with an activation function (more on why this works can be found further down): . np.random.seed(2) def relu(x): return (x&gt;0)*x def relu_prime(x): return x&gt;0 def nn(X, y, hidden_size , lr=0.01): print(f&#39;True values: {y} n&#39;) n = y.shape[1] W1 = np.random.randn(X.shape[1], hidden_size) W2 = np.random.randn(hidden_size, 1) for i in range(100): z1 = X.dot(W1) a1 = relu(z1) z2 = a1.dot(W2) # predictions mse = (1/2)*np.mean((y-z2)**2) if i % 10 == 0: print(&#39;Mean Squared Error:&#39;, round(mse, 3)) dZ2 = (y-z2) dW2 = a1.T.dot(dZ2) W2 += lr*dW2 dZ1 = (dZ2.dot(W2.T))*relu_prime(a1) dW1 = X.T.dot(dZ1) W1 += lr*dW1 #(1/n) print(&#39; nW1:&#39;, np.round(W1, 3)) print(&#39;W2:&#39;, np.round(W2, 3)) print(&#39; nFinal predictions:&#39;, np.round(z2, 2)) X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]]) y = np.array([[1, 1, 0, 0]]).T nn(X, y, 4) . True values: [[1] [1] [0] [0]] Mean Squared Error: 1.12 Mean Squared Error: 0.284 Mean Squared Error: 0.133 Mean Squared Error: 0.078 Mean Squared Error: 0.052 Mean Squared Error: 0.037 Mean Squared Error: 0.027 Mean Squared Error: 0.021 Mean Squared Error: 0.016 Mean Squared Error: 0.012 W1: [[-0.417 -0.056 -2.136 0.599] [-1.793 -0.842 0.847 -1.302]] W2: [[-1.058] [-0.909] [ 0.876] [ 1.738]] Final predictions: [[1.04] [0.74] [0. ] [0. ]] . What is universality? . Universality is the ability to compute any arbitrary function. | . It has been proven that any function we can think of can be approximated by a neural network with at least two layers. . Michael Nielsen clarifies two caveats related to this idea of universality: . Universality doesn&#39;t mean that the neural network is guaranteed to be exact, instead we are approximating the function and the more neurons we add the closer it gets to the true function. This means that for any function f(X) and any error threshold we define we can always find a neural network with output g(x) that satisfies: | $$ |g(x) - f(x)| &lt; epsilon $$ . Neural networks approximate continuous functions. Functions that are not continuous with sharp and sudden jumps won&#39;t be approximated by a neural network as a general rule. But that doesn&#39;t mean that we can often use a continuous approximation that is good enough for our given purposes when trying to approximate a discontinuous function. |",
            "url": "https://kallebylin.github.io/bylin/deep-learning/2021/03/01/dl-notes.html",
            "relUrl": "/deep-learning/2021/03/01/dl-notes.html",
            "date": " • Mar 1, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://kallebylin.github.io/bylin/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kallebylin.github.io/bylin/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}