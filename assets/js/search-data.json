{
  
    
        "post0": {
            "title": "Pruebas A/B - Fundamentos",
            "content": "&#191;Qu&#233; es una prueba A/B? . . En pocas palabras, una prueba A/B es una comparación entre dos alternativas con el objetivo de descubrir cuál es mejor. . Cuando tomamos decisiones es muy fácil dejarnos llevar por nuestras opiniones. Esto no siempre es malo, pero es especialmente peligroso en empresas cuando una iniciativa es seleccionada basado principalmente en la opinión de la persona con mayor poder jerárquico en lugar del mérito propio de la iniciativa. . A lo largo de este documento vamos a presentar también ciertas reglas importantes durante el proceso de comparación que nos permiten tener confianza en el resultado. . Voy a enfocarme principalmente en decisiones relacionadas al desarrollo de productos digitales, pero es aplicable en muchos otros contextos. . Es una herrmiante de toma de decisiones | . El valor principal de una prueba A/B nace de la incertidumbre inherente de nuestras decisiones. Cuando no estamos seguros de qué camino tomar, una prueba A/B es una manera efectiva de probar ambas alternativas por un tiempo y dejar que los resultados nos guíen. . Es un acelerador de procesos | . El riesgo y la incertidumbre suelen volver lentos nuestros procesos. Cuando hay riesgo de algo potencialmente dañino para la compañía se vuelve importante crear procesos de verificación y puntos de control antes de lanzar una iniciativa. Desarrollando software es común usar una mezcla entre pruebas automatizadas y revisiones de código. . El problema es que por cada persona que tiene que entrar a revisar el trabajo tardas más en sacar la iniciativa a producción y esas personas pierden la posibilidad de estar trabajando en otra cosa. . Una prueba A/B reduce el riesgo porque te permite controlar el daño potencial y te permite justificar tus decisiones. Esto se puede hacer, por ejemplo, corriendo el experimento con únicamente 5% de tus usuarios. . Además, al comparar los resultados de tu experimento es más fácil darse cuenta si la iniciativa está teniendo un impacto negativo en alguna métrica clave. Sin un punto de comparación suele ser muy difícil saber si un cambio negativo en una métrica se debe a la implementación o algún otro factor. . Empodera personas | . El uso constante de pruebas A/B reduce la necesidad de que una sola persona tome decisiones y permite a cualquier miembro del equipo aportar ideas. Se vuelve menos importante si alguien piensa que es una buena o mala idea, el desempeño de la idea en el campo de batalla es el juez final srgún los datos recolectados. .",
            "url": "https://kallebylin.github.io/bylin/spanish/data-science/ab-testing/2021/04/17/ab-testing-basics-spanish.html",
            "relUrl": "/spanish/data-science/ab-testing/2021/04/17/ab-testing-basics-spanish.html",
            "date": " • Apr 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Computational Learning Theory - Notes",
            "content": "About . There are good and bad practices for human learning. Highlighting interesting quotes in a book usually makes us feel productive in the moment but, let&#39;s be honest, doesn&#39;t help much in terms of learning. . Taking notes, on the other hand, is a much more effective way of interiorizing information and storing it in long-term memory, especially if we translate concepts with our own words instead of just copying a text. . The same is true for learning algorithms, not the part about taking notes but the fact that there ar good and bad methods for learning. Computational Learning Theory (also known as Statistical Learning Theory) is a branch of computer science focused on understanding how computational learning can happen efficiently and effectively, as well as discovering different impediments to learning. . This document contains my notes on Computational Learning Theory. . Is bias always a bad thing? . Bias usually has a very negative connotation, often thought of as prejudice and we are encouraged to always keep an open mind. . But don&#39;t confuse an open mind with an empty mind. We often learn by building new ideas on top of other ideas we have learned in the past. Keeping an open mind means that we have to remember that some of our foundational building blocks might be wrong and need to be corrected. But constantly throwing away previous knowledge would make learning practically impossible. . Pigeon superstition . One of B.F. Skinner&#39;s classical experiments supposedly showed &quot;superstitious&quot; behavior by pigeons. The experiment consisted in providing food to hungry pigeons in a cage through a mechanism that was guaranteed to be completely independent from any behavior by the pigeons. . &quot;If a clock is now arranged to present the food hopper at regular intervals with no reference whatsoever to the bird&#39;s behavior, operant conditioning usually takes place. The bird tends to learn whatever response it is making when the hopper appears. The response may be extinguished and reconditioned. The experiment might be said to demonstrate a sort of superstition. The bird behaves as if there were a causal relation between its behavior and the presentation of food, although such a relation is lacking&quot;. . Skinner, B. F. (1948). &#39;Superstition&#39; in the pigeon. Journal of Experimental Psychology, 38(2), 168–172. . Let&#39;s say one of the pigeons was pecking on a prticular stain on the bottom of the cage when the first round of food was released. According to Skinner, the pigeon was then more likely to repeat this same behavior which, in turn, also made it more likely for the pigeon to be found pecking on the stain when the next round of food was released. . Amusingly, each pigeon showed a different type of behavior that was reinforced (walking around the cage in a specific direction, bobbing the head, etc.) as if the behavior was causing more food to be released. We know that this is not the case, because the food was being released at regular pre-defined intervals. . This can then be compared to different forms of human superstition. Have you or anybody you known ever had a special ritual at home before every game of our favorite football team? =D . Rats and selective association . The phenomenon above can be compared to the behavior of rats as studied by Garcia and Koelling in 1966. Imagine rats going for their regular snack. Some of the rats were then induced to feel ill through an injection or radiation. As could be expected these rats then avoided food with similar taste or smell in the future. . Another batch of rats was administered a mild electrical shock in the foot. Interestingly, these rats did not show aversion to the food or water, but instead to an audiovisual cue that always happened while they were eating or drinking. . This experiment is widely known as one of the first proofs of the so-called Selective Association Effect. This is related to the concept of biological constraints disccused by students of Skinner. Apparently some animals naturally resist certain types of conditioning, as if they had some kind of built in prior knowledge that some types of relationships could not causal. . Inductive bias . This takes us to the concept of inductive bias, which can be described as the set of assumptions or prior knowledge that biases learning by setting restrictions or constraints to the learning process. . In our example, the rats seem to be biased towards detecting certain types of patterns between taste or smell and their health, while ignoring other types of seemingly correlated events. . This is a well known concept in machine learning. We often talk about models that have high bias or high variance. The second type of models tend to be more complex and are more flexible in the type of functions they can model. But this often makes them more difficult to interpret or prone to overfitting (they memorize the training data, which in this case can be compared to finding superstitious patterns that only apply to that particular set of data). . By restricting the types of patterns we are looking for we can often make the learning process easier and also extract valuable insights from the trained model. Linear regression is a great example with well-known assumptions and very powerful applications. . Deductive vs Inductive reasoning . Just as a refresher, we can think about deductive and inductive reasoning as taking to different routes (often described as top-down or bottom-up approaches). . On one hand (deduction) we start with general theories about how things should work, we develop a hypothesis that we can then confirm through experiments and specific observations. . Deductive reasoning:- Theory -&gt; Hypothesis -&gt; Observations -&gt; Confirmation . On the other hand, we might start with specific observations which we then use to try to discover a pattern in those observations. These patterns that we discover can then lead us to a more generalized understanding of the world. . Inductive reasoning: . Observations -&gt; Pattern -&gt; Tentative Hypothesis -&gt; Theory | . Statistical Learning Theory . In statistics it is common to to have well-defined assumptions about the distribution of our data (e.g. Gaussians). In SLT we have no or very general assumptions. . Is all learning equal? . Intuitively it would seem that there are different ways of learning. More formally, we can separate learning by different levels: . Reproductive learning | It could be argued that this first level is not learning at all. . Basically, imagine a class where students are allowed to to take all of their notes to class. It would be possible for a student to create a table with all the information he needs without interiorizing the concepts. Once the exam starts he simply looks up the answers to his questions in the table. So he basically reproduces the information. . The negative side is that we need to store all of the relevant information beforehand. This can in many cases be very difficult or even impossible. . Rule-based learning | This level of learning can be thought of as encoding the knowledge of experts. Imagine a medical application created to automatically diagnose different types of diseases. One way to do this would be to get input from a group of doctors and create a flow-chart with nodes for every single decision that could be made. . Now we don&#39;t need to store the raw data or the observations with their corresponding labels as we would do in reproductive learning. Instead we keep all of these rules that can lead us to an answer. . The problem with this approach is that it is also very difficult or even impossible to encode every single use case and the rules are often very brittle. . Creative learning | Here past experience is combined in different ways to solve new problems. This can often be a much more powerful approach as we are not limited to only reproducing past observations or following rigid rules. . The main issue here is that it can be quite difficult to explain why a decision has been made. . &quot;If the true classifier is a halfspace, then we should be able to find a very precise separation line with only a few random examples.&quot; . 1-nearest neighbor algorithm . In this extreme example we store all observations and their lables. Any new lable receives the label of the closest point. Two main conclusions we notice are:- This algorithm will always classify all training samples correctly. . This algorithm will also be able to approximate any smooth function, even where halfspace classifiers perform poorly. | . def true_classifier(point) : return int(point[0] &gt;= 0) def nearest_neighbor(train_set, test_point): closest_dist = float(&#39;inf&#39;) closest = -1 for features, label in train_set: dist = sum([(p2-p1)**2 for p1,p2 in list(zip(features, test_point))]) if dist &lt; closest_dist: closest_dist = dist closest = label label = closest return label def error_probability(train_set) : mistakes = 0 no_test_points = 2000 for i in range(0,no_test_points): point = (2*i/no_test_points - 1,) if true_classifier(point) != nearest_neighbor(train_set, point) : mistakes += 1 return mistakes/no_test_points train_inputs = [-1.0, -0.1, 0.1] new_input = -0.0001 #-0.0010000000000000009 S = [((x_val,), true_classifier((x_val,))) for x_val in train_inputs] error_S = error_probability(S) new_point = (new_input,) S.append( (new_point, true_classifier(new_point)) ) print(error_S, error_probability(S)) assert error_S &lt; error_probability(S) . 0.0005 0.025 .",
            "url": "https://kallebylin.github.io/bylin/machine-learning/computational-learning-theory/2021/03/09/computational-learning-theory.html",
            "relUrl": "/machine-learning/computational-learning-theory/2021/03/09/computational-learning-theory.html",
            "date": " • Mar 9, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Deep Learning - Notes",
            "content": "About . This notebook contains my notes for introductory DL concepts. . What is a perceptron? . Perceptrons were originally brain models created to understand how the brain works. A perceptron as we know it encodes several principles about how the brain works and then evolved into an algorithm for supervised binary classification. | . In the 1960&#39;s, Frank Rosenblatt published the book Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. It is curious that this fundamental block for AI was, in the author&#39;s mind, a tool for understanding the human brain and not for pattern recognition (even though he encouraged this use as well): . For this writer, the perceptron program is not primarily concerned with the invention of devices for &quot;artificial intelligence&quot;, but rather with investigating the physical structures and neurodynamic principles which underlie &quot;natural intelligence&quot;. A perceptron is first and foremost a brain model, not an invention for pattern recognition [emphasis added]&quot; (p. viii). . In other words, the perceptron is actually a simplification and abstraction which has allowed us to discover principles for how the brain works. These same principles were then also used to create pattern recognition machines. . Rosenblatt explicitly recognizes that his model is a direct descendant of the model created by McCulloch and Pitts, and influenced by the theories of Hebb and Hayek. . Main components of a perceptron in Rosenblatt&#39;s book:- Environment: The environment generates the information that is initially passed on to the perceptron. . Signal generating units: Each unit receives a signal and generates an output signal. | . Signal propagation functions: These are rules that define how signals are generated and transmitted. | . Memory functions: These are rules that define how properties of the perceptron can be changed in response to certain activity. | . The definition of a single neuron evolves from the ideas above. . A neuron takes values from its environment (e.g. x1, x2, x3) and each of these gets multiplied by a stored parameter (e.g. w1, w2, w3). The sum of each of these operations is then passed through an activation function. . In other words, it&#39;s as if we are trying to pass a signal through the neuron and all of these components work together to establish how the signal is transmitted. . We can imagine three old batteries used to turn on a machine. Turning it on with too little energy could cause it to break, so we check the current before passing it on to the machine. . . In the example below, we are randomly initializing the parameters. The activation function is a step-function with a threshold of 4. This means that the signal is only passed on as a unitary value if it is larger than or equal to the threshold. . import numpy as np w1 = np.random.random()*2 # generates random floats between 0 and 2 w2 = np.random.random()*2 w3 = np.random.random()*2 print(f&#39;W1 is equal to: {w1}&#39;) print(f&#39;W2 is equal to: {w2}&#39;) print(f&#39;W3 is equal to: {w3} n&#39;) x1 = 2 x2 = 1 x3 = 3 b = 0 activation_function = lambda x: 1 if x &gt;=4 else 0 output = activation_function(x1*w1 + x2*w2 + x3*w3) print(&#39;Output:&#39;, output) if output == 1: print(&#39;The machine is on!&#39;) else: print(&#39;Not enough energy to turn on the machine :(&#39;) . W1 is equal to: 0.6321002815675523 W2 is equal to: 1.6995522179113192 W3 is equal to: 1.2072466687862997 Output: 1 The machine is on! . What is an activation function? . Going back to Rosenblatt&#39;s book, activation functions are essentially signal propagation functions. . When a neuron receives a signal, the activation function decides if the signal is passed on and how strong the output signal becomes. . We already learned about the step function. This activation is often not ideal for multiple reasons. . First of all, the result is binary. But sometimes we are more interested in also knowing the degree of certainty, so I probability might be better. . We might also want to have a wider range of values. When predicting age, for example, binary values of 0 or 1 will be of little value. . A lot of different activation functions have been developed by researchers. Three common activation functions are: . Sigmoid function Has a great property of having outputs between 0 and 1 and therefore can be interpreted as probabilities. The function is also smooth and easy to differentiate which makes learning easier. . It can be problematic when the input signal has very large positive or negative values. At those points the derivative is very close to 0 and learning becomes very slow. . Hyperbolic function This is another smooth function with a range of values between -1 and 1. This is interesting because sometimes a signal might have a reverse effect on the output and the hyperbolic function allows us to include this type of relationship in the network. . Rectified linear unit (ReLU) This function is very simple aned fast to compute. This allows us to work with larger and more complex models that, given enough data, can produce better results overall. . What is a neural network? . A neural network is a directed system of connected neurons which is capable of propagating a signal received from the environment and produces an output signal. | . The neurons are generally organized in different layers which allow us to break free from linearity. . Linearity means that we are also assuming monotonicity. In other words, an increase in an input value always increases the output value if the corresponding weight is positive (and will always decrease the output value if the weight is negative). . This works fine in examples like the one seen above where we turn on a lightbulb depending on how much energy we get from each battery. . But this makes less sense in other cases. For examples very pronounced sales spikes in an online marketplace followed by no sales at all could be indicative of fraud. A positive value for a feature describing this type of spikes should increase the probability of fraud. . But is this always the case? . What if we additionally know that the owner of the store is a web celeb (网红) on Alibaba? In that case the spikes above are expected, and therefore a positive value for this feature should decrease the probability of fraud while any other behavior might be suspicious. . Let&#39;s build a neural network step by step: . The simplest example is a single neuron with only one parameter which does not modify the signal in any way: . def nn(x, w): return w*x print(nn(3, 6)) . 18 . Most processes we find in the real world are not this simple. We need to take into account multiple input features. . I love music, imagine I want to predict if I will like a particular song or not. We can quickly multiply each input value by its corresponding weight using a dot product. . def nn(X, W): return W.dot(X) x1 = 3.5 # length of songs in minutes x2 = 0 # binary value indicating if the genre is jazz or not x3 = 0 # binary value indicating if the artist is Nicki Minaj or not x4 = 1 # binary value indicating if the artist is Alan Walker X = np.array([x1, x2, x3, x4]) W = np.array([1., 0.3, -3, 4]) print(nn(X, W)) . 7.5 . What is interesting above is that the weights actually encode certain information about my taste in music. I really don&#39;t like when a song is too short and, in general, I&#39;m not fond of music by Nicki Minaj (notice the negative weight). But I do love music by Alan Walker. Jazz is nice but I don&#39;t love it. . Now the real question is, how do we know the values of these weights. In this case, I used my deep expertise regarding my own music taste to set the weights. But we would usually be more interested in doing this for the users of our streaming platform at scale. Millions of people we have never and will probably never meet in person. . So, first we&#39;re going to change the output. We want to predict if a particular user is going to like a song or not. Using the sigmoid function we can directly compare the true values (0 or 1) to our predictions (floats between 0 and 1). . We will also initialize the weights randomly and print out an error value showing how close our prediction is to the true value: . def nn(X, y, W): prediction = W.dot(X) error = y-prediction print(&#39;Predicted value:&#39;, round(prediction, 3)) print(&#39;Error:&#39;, round(error, 3)) x1 = 3.5 # length of songs in minutes x2 = 0 # binary value indicating if the genre is jazz or not x3 = 0 # binary value indicating if the artist is Nicki Minaj or not x4 = 1 # binary value indicating if the artist is Alan Walker X = np.array([x1, x2, x3, x4]) y = 5 W = np.random.random(size=4)*2-1 nn(X, y, W) . Predicted value: -1.468 Error: 6.468 . It&#39;s now time to start talking about learning or how our neural network is going to choose the best parameters during training to make accurate predictions. . We will follow a very simple framework of three steps: . Predict | Compare | Learn | This time we will add multiple iterations to our algorithm and we will do the three steps above during each iteration. . def nn(X, y, W): print(f&#39;True value: {y} n&#39;) for i in range(10): prediction = W.dot(X) error = y-prediction print(&#39;Predicted value:&#39;, round(prediction, 3)) print(&#39;Error:&#39;, round(error, 3)) if error &gt; 0: W += 0.01 else: W -= 0.01 x1 = 3.5 # length of songs in minutes x2 = 0 # binary value indicating if the genre is jazz or not x3 = 0 # binary value indicating if the artist is Nicki Minaj or not x4 = 1 # binary value indicating if the artist is Alan Walker X = np.array([x1, x2, x3, x4]) y = 1 W = np.random.random(size=4)*2-1 nn(X, y, W) . True value: 1 Predicted value: 0.116 Error: 0.884 Predicted value: 0.161 Error: 0.839 Predicted value: 0.206 Error: 0.794 Predicted value: 0.251 Error: 0.749 Predicted value: 0.296 Error: 0.704 Predicted value: 0.341 Error: 0.659 Predicted value: 0.386 Error: 0.614 Predicted value: 0.431 Error: 0.569 Predicted value: 0.476 Error: 0.524 Predicted value: 0.521 Error: 0.479 . Here we are doing hot &amp; cold learning. After each prediction we are making a comparison just like in the classical game so that we get &quot;hotter&quot; or closer to the true answer after each guess. . The way we are calculating the error makes it negative if it was too high or positive if our guess was too low. . We can now be a bit smarter in the way we learn. Instead of guessing and trying to jiggle the output to both sides, we can use the gradient to guide us: . def nn(X, y, W): print(f&#39;True values: {y} n&#39;) n = y.shape[1] for i in range(100): predictions = W.dot(X.T) mse = (1/2)*np.mean((y-predictions)**2) if i % 10 == 0: print(&#39;Mean Squared Error:&#39;, round(mse, 3)) dW = -(1/n)*(y-predictions).dot(X) W -= 0.1*dW print(&#39; nW:&#39;, np.round(W, 3)) print(&#39; nFinal predictions:&#39;, np.round(predictions, 2)) X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]]) y = np.array([[1, 0, 0, 1]]) W = np.random.randn(1, 2) nn(X, y, W) . True values: [[1 0 0 1]] Mean Squared Error: 0.234 Mean Squared Error: 0.132 Mean Squared Error: 0.078 Mean Squared Error: 0.046 Mean Squared Error: 0.028 Mean Squared Error: 0.017 Mean Squared Error: 0.01 Mean Squared Error: 0.006 Mean Squared Error: 0.004 Mean Squared Error: 0.002 W: [[0.927 0.073]] Final predictions: [[0.92 0.07 0. 1. ]] . This version led us quickly very close to the correct answers. But we now have another problem. The previous problem was very easy to learn because one of the features had a direct 1-on-1 relationship with an output. A simple linear function was capable of leveraging that feature. . Let&#39;s look at the next example: . X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]]) y = np.array([[1, 1, 0, 0]]) W = np.random.randn(1, 2) nn(X, y, W) . True values: [[1 1 0 0]] Mean Squared Error: 0.863 Mean Squared Error: 0.572 Mean Squared Error: 0.408 Mean Squared Error: 0.311 Mean Squared Error: 0.254 Mean Squared Error: 0.219 Mean Squared Error: 0.198 Mean Squared Error: 0.186 Mean Squared Error: 0.178 Mean Squared Error: 0.174 W: [[0.462 0.204]] Final predictions: [[0.47 0.2 0. 0.67]] . MSE might not be extremely high but the answers are terrible. This is because the new problem we&#39;re working with cannot be solved with a simple linear function. So, to solve this we can add a hidden layer with an activation function (more on why this works can be found further down): . np.random.seed(2) def relu(x): return (x&gt;0)*x def relu_prime(x): return x&gt;0 def nn(X, y, hidden_size , lr=0.01): print(f&#39;True values: {y} n&#39;) n = y.shape[1] W1 = np.random.randn(X.shape[1], hidden_size) W2 = np.random.randn(hidden_size, 1) for i in range(100): z1 = X.dot(W1) a1 = relu(z1) z2 = a1.dot(W2) # predictions mse = (1/2)*np.mean((y-z2)**2) if i % 10 == 0: print(&#39;Mean Squared Error:&#39;, round(mse, 3)) dZ2 = (y-z2) dW2 = a1.T.dot(dZ2) W2 += lr*dW2 dZ1 = (dZ2.dot(W2.T))*relu_prime(a1) dW1 = X.T.dot(dZ1) W1 += lr*dW1 #(1/n) print(&#39; nW1:&#39;, np.round(W1, 3)) print(&#39;W2:&#39;, np.round(W2, 3)) print(&#39; nFinal predictions:&#39;, np.round(z2, 2)) X = np.array([[1, 0], [0, 1], [0, 0], [1, 1]]) y = np.array([[1, 1, 0, 0]]).T nn(X, y, 4) . True values: [[1] [1] [0] [0]] Mean Squared Error: 1.12 Mean Squared Error: 0.284 Mean Squared Error: 0.133 Mean Squared Error: 0.078 Mean Squared Error: 0.052 Mean Squared Error: 0.037 Mean Squared Error: 0.027 Mean Squared Error: 0.021 Mean Squared Error: 0.016 Mean Squared Error: 0.012 W1: [[-0.417 -0.056 -2.136 0.599] [-1.793 -0.842 0.847 -1.302]] W2: [[-1.058] [-0.909] [ 0.876] [ 1.738]] Final predictions: [[1.04] [0.74] [0. ] [0. ]] . What is universality? . Universality is the ability to compute any arbitrary function. | . It has been proven that any function we can think of can be approximated by a neural network with at least two layers. . Michael Nielsen clarifies two caveats related to this idea of universality: . Universality doesn&#39;t mean that the neural network is guaranteed to be exact, instead we are approximating the function and the more neurons we add the closer it gets to the true function. This means that for any function f(X) and any error threshold we define we can always find a neural network with output g(x) that satisfies: | $$ |g(x) - f(x)| &lt; epsilon $$ . Neural networks approximate continuous functions. Functions that are not continuous with sharp and sudden jumps won&#39;t be approximated by a neural network as a general rule. But that doesn&#39;t mean that we can often use a continuous approximation that is good enough for our given purposes when trying to approximate a discontinuous function. |",
            "url": "https://kallebylin.github.io/bylin/deep-learning/2021/03/01/dl-notes.html",
            "relUrl": "/deep-learning/2021/03/01/dl-notes.html",
            "date": " • Mar 1, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://kallebylin.github.io/bylin/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://kallebylin.github.io/bylin/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}